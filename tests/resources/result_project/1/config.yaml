node_lines:
  - node_line_name: pre_retrieve_node_line  # Arbitrary node line name
    nodes:
      - node_type: query_expansion
        strategy:
          metrics: [ retrieval_f1, retrieval_recall, retrieval_precision ]
          speed_threshold: 10
          top_k: 10
          retrieval_modules:
            - module_type: bm25
            - module_type: vectordb
              vectordb: default
        modules:
          - module_type: query_decompose
            llm: openai
            temperature: [ 0.2, 1.0 ]
          - module_type: hyde
            llm: openai
            max_token: 64
  - node_line_name: retrieve_node_line  # Arbitrary node line name
    nodes:
      - node_type: retrieval
        strategy:
          metrics: [ retrieval_f1, retrieval_recall, retrieval_precision ]
          speed_threshold: 10
        top_k: 10
        modules:
          - module_type: bm25
          - module_type: vectordb
            vectordb: default
      - node_type: passage_reranker
        strategy:
          metrics: [ retrieval_f1, retrieval_recall, retrieval_precision ]
          speed_threshold: 10
        top_k: 5
        modules:
          - module_type: tart
          - module_type: monot5
      - node_type: passage_filter
        strategy:
          metrics: [ retrieval_f1, retrieval_recall, retrieval_precision ]
          speed_threshold: 5
        modules:
          - module_type: pass_passage_filter
          - module_type: threshold_cutoff
            threshold: 0.85
  - node_line_name: post_retrieve_node_line  # Arbitrary node line name
    nodes:
      - node_type: prompt_maker
        strategy:
          metrics: [ bleu, meteor, rouge ]
          speed_threshold: 10
          generator_modules:
            - module_type: llama_index_llm
              llm: mock
        modules:
          - module_type: fstring
            prompt: [ "Tell me something about the question: {query} \n\n {retrieved_contents}",
                      "Question: {query} \n Something to read: {retrieved_contents} \n What's your answer?" ]
      - node_type: generator
        strategy:
          metrics: [ bleu, meteor, rouge ]
          speed_threshold: 10
        modules:
          - module_type: llama_index_llm
            llm: [ mock ]
