# In this yaml, we do not use tree_summarize for accuracy
# And did not use monoT5, because it can take too long.
node_lines:
  - node_line_name: retrieve_node_line
    nodes:
      - node_type: retrieval
        strategy:
          metrics: [ retrieval_f1, retrieval_recall, retrieval_precision ]
        top_k: 20
        modules:
          - module_type: bm25
          - module_type: vectordb
            embedding_model: openai
          - module_type: hybrid_rrf
          - module_type: hybrid_cc
            normalize_method: [ mm, tmm, z, dbsf ]
      - node_type: passage_reranker
        strategy:
          metrics: [ retrieval_f1, retrieval_recall, retrieval_precision ]
        top_k: 3
        modules:
          - module_type: pass_reranker
          - module_type: tart
          - module_type: upr
          - module_type: cohere_reranker
  - node_line_name: post_retrieve_node_line
    nodes:
      - node_type: prompt_maker
        strategy:
          metrics:
            - metric_name: bleu
            - metric_name: meteor
            - metric_name: rouge
            - metric_name: sem_score
              embedding_model: openai
          generator_modules:
            - module_type: llama_index_llm
              llm: openai
              batch: 2
        modules:
          - module_type: fstring
            prompt:
              - "Answer to given questions with the following passage: {retrieved_contents} \n\n Question: {query} \n\n Answer:"
              - "There is a passages related to user question. Please response carefully to the following question. \n\n Passage: {retrieved_contents} \n\n Question: {query} \n\n Answer the question. Think step by step." # Zero-shot CoT prompt
              - "{retrieved_contents} \n\n Read the passage carefully, and answer this question. \n\n Question: {query} \n\n Answer the question. Be concise." # concise prompt
      - node_type: generator
        strategy:
          metrics:
            - metric_name: bleu
            - metric_name: meteor
            - metric_name: rouge
            - metric_name: sem_score
              embedding_model: openai
            - metric_name: g_eval
        modules:
          - module_type: llama_index_llm
            llm: openai
            temperature: [ 0.1, 0.5, 1.1 ]
            batch: 2
